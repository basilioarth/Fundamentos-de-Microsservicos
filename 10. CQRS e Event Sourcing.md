# Resumo da Aula sobre CQRS e Event Sourcing em Microserviços

## Introdução
A aula apresenta o **CQRS (Command Query Responsibility Segregation)** como uma solução alternativa ao **Backend for Frontend (BFF)** para combinar dados de múltiplos serviços em microserviços, focando na separação de responsabilidades entre operações de escrita (comandos) e leitura (consultas). O padrão é complementado pelo **Event Sourcing**, que armazena eventos em vez de estados finais, permitindo reconstruir o estado dos dados em um banco de leitura otimizado. O exemplo utiliza serviços de **Pedidos**, **Notas Fiscais** e **Estoque**, com tabelas de visualização (View Tables) para consultas eficientes. A implementação não está detalhada no código do projeto, mas é referenciada na pasta `docs` e no site [Microservices.io](https://microservices.io/). Ferramentas de *Data Warehouse* e eventos Kafka são usadas para popular as tabelas de leitura.

## Conceitos Fundamentais
- **CQRS (Command Query Responsibility Segregation)**:
  - Separa operações de escrita (comandos: CREATE, UPDATE, DELETE) de operações de leitura (consultas: GET).
  - **Objetivo**: Otimizar a arquitetura de microserviços, onde cada serviço lida apenas com comandos, enquanto um banco de dados dedicado (View Tables) gerencia consultas.
  - **Benefícios**:
    - Desacopla a lógica de escrita e leitura, permitindo escalabilidade independente.
    - Simplifica consultas complexas que envolvem múltiplos serviços.
    - Melhora a performance de leituras ao usar tabelas otimizadas.
  - **Exemplo**: O serviço de Pedidos só processa comandos (ex.: criar pedido), enquanto um banco de leitura (`orders_with_invoices`) fornece dados combinados para o front-end.
- **View Tables**:
  - Tabelas otimizadas para leitura, populadas automaticamente com dados de múltiplos serviços.
  - Exemplo: Tabela `orders_with_invoices` contém `order_id`, `customer_name`, `created_at`, `invoice_url`, já formatada para o front-end.
  - Populadas por ferramentas de *Data Warehouse* ou pipelines de eventos (ex.: Kafka).
- **Event Sourcing**:
  - Em vez de armazenar o estado final (ex.: estoque atual de um produto), armazena a sequência de eventos que levaram a esse estado (ex.: `increase`, `decrease`).
  - **Objetivo**: Registrar o histórico de mudanças como eventos, permitindo reconstruir o estado atual em um banco de leitura.
  - **Exemplo**: No serviço de Estoque, a tabela `ProductStockOperations` armazena eventos como `{ product_id: 1, stock_amount: 3, operation: 'increase', created_at: '2025-08-13' }`.
  - **Integração com CQRS**: Eventos são enviados (ex.: via Kafka) para um banco de leitura, que processa os eventos e atualiza as View Tables (ex.: atualiza o estoque na tabela `products`).
- **Problema Resolvido**:
  - **Sem CQRS**: O front-end ou um BFF faria múltiplas chamadas (ex.: buscar pedidos, depois notas fiscais), aumentando latência e complexidade.
  - **Com CQRS**: O front-end faz uma única requisição GET a um serviço de leitura, que acessa a View Table com dados pré-combinados, reduzindo latência e simplificando a lógica.

## Exemplo Prático
- **Cenário: Listagem de Pedidos com Notas Fiscais**:
  - **Serviços Envolvidos**:
    - **Pedidos**: Processa comandos (ex.: criar pedido) e armazena eventos (ex.: `order.created`).
    - **Notas Fiscais**: Processa comandos (ex.: emitir nota fiscal) e armazena eventos (ex.: `invoice.created`).
    - **Estoque**: Processa comandos (ex.: atualizar estoque) e armazena eventos (ex.: `stock.increased`, `stock.decreased`).
    - **Serviço de Leitura**: Acessa uma View Table (`orders_with_invoices`) para consultas do front-end.
  - **Fluxo com CQRS**:
    1. Cada serviço (Pedidos, Notas Fiscais, Estoque) processa comandos e publica eventos no Kafka:
       - Ex.: Pedidos publica `order.created { order_id: 1, customer_name: 'João', created_at: '2025-08-13' }`.
       - Notas Fiscais publica `invoice.created { order_id: 1, invoice_url: 'http://...' }`.
    2. Um pipeline de *Data Warehouse* (ou consumidor Kafka) processa os eventos e popula a View Table `orders_with_invoices`:
       - Ex.: `{ order_id: 1, customer_name: 'João', created_at: '2025-08-13', invoice_url: 'http://...' }`.
    3. O front-end faz uma requisição GET ao serviço de leitura (ex.: `GET /orders-with-invoices?userId=123`), que consulta a View Table e retorna os dados combinados.
  - **Fluxo com Event Sourcing (Estoque)**:
    1. O serviço de Estoque armazena eventos em `ProductStockOperations`:
       - Ex.: `{ product_id: 1, stock_amount: 3, operation: 'increase', created_at: '2025-08-13' }`.
       - Ex.: `{ product_id: 1, stock_amount: 1, operation: 'decrease', created_at: '2025-08-14' }`.
    2. Um consumidor Kafka processa os eventos e atualiza a View Table `products`:
       - Ex.: Calcula o estoque atual (3 - 1 = 2) e atualiza `{ product_id: 1, stock: 2 }`.
    3. O front-end consulta a View Table para exibir o estoque atual.
  - **Resultado**:
    - O front-end faz uma única requisição ao serviço de leitura, recebendo dados pré-combinados.
    - Os serviços de escrita (Pedidos, Notas Fiscais, Estoque) focam em comandos, enquanto o serviço de leitura otimiza consultas.
- **Diferença do BFF**:
  - **BFF**: Agrega dados em tempo real, fazendo chamadas síncronas (ex.: gRPC) aos serviços.
  - **CQRS**: Usa um banco de leitura pré-populado, eliminando chamadas síncronas e reduzindo latência.

## Implementação no Código
- **Estrutura do Projeto**:
  - **Serviços de Escrita (Pedidos, Notas Fiscais, Estoque)**:
    - Processam comandos (CREATE, UPDATE, DELETE) e publicam eventos no Kafka.
    - Exemplo: Pedidos publica `order.created` com `order_id`, `customer_name`, `created_at`.
    - Não possuem rotas GET para consultas.
  - **Serviço de Leitura**:
    - Acessa View Tables (ex.: `orders_with_invoices`) para consultas.
    - Rota: `GET /orders-with-invoices?userId=X`.
    - Retorna dados combinados no formato esperado pelo front-end.
  - **View Tables**:
    - Tabelas otimizadas (ex.: `orders_with_invoices`) em um banco de leitura (ex.: PostgreSQL, Elasticsearch).
    - Populadas por um pipeline de *Data Warehouse* ou consumidor Kafka.
  - **Event Sourcing**:
    - Tabelas como `ProductStockOperations` armazenam eventos (ex.: `{ product_id, stock_amount, operation, created_at }`).
    - Um consumidor Kafka processa eventos e atualiza View Tables (ex.: `products` com estoque atual).
  - **Docs**: A pasta `docs` contém explicações sobre CQRS e Event Sourcing, com diagramas e referências ao [Microservices.io](https://microservices.io/patterns/data/cqrs.html).
- **Código (Exemplo Conceitual)**:
  - **Serviço de Escrita (Pedidos)**:
    ```javascript
    async function createOrder(orderData) {
      await db.orders.insert(orderData);
      await kafka.send('order.created', { order_id: orderData.id, customer_name: orderData.customer_name, created_at: now });
    }
    ```
  - **Serviço de Leitura**:
    ```javascript
    async function getOrdersWithInvoices(userId) {
      return await db.orders_with_invoices.find({ where: { user_id: userId } });
    }
    ```
  - **Consumidor Kafka (Popula View Table)**:
    ```javascript
    kafka.consume('order.created', async (event) => {
      const invoice = await db.invoices.find({ where: { order_id: event.order_id } });
      await db.orders_with_invoices.insert({
        order_id: event.order_id,
        customer_name: event.customer_name,
        created_at: event.created_at,
        invoice_url: invoice?.url || null
      });
    });
    ```
  - **Event Sourcing (Estoque)**:
    ```javascript
    async function updateStock(productId, amount, operation) {
      await db.product_stock_operations.insert({ product_id, stock_amount: amount, operation, created_at: now });
      await kafka.send('stock.updated', { product_id, stock_amount, operation });
    }
    ```
    ```javascript
    kafka.consume('stock.updated', async (event) => {
      const currentStock = await db.products.find({ where: { product_id: event.product_id } });
      const newStock = event.operation === 'increase' ? currentStock.stock + event.stock_amount : currentStock.stock - event.stock_amount;
      await db.products.update({ stock: newStock }, { where: { product_id: event.product_id } });
    });
    ```
  - **Nota**: A implementação é conceitual, referenciada na pasta `docs` e no [Microservices.io](https://microservices.io/patterns/data/cqrs.html).
- **Kafka**:
  - Publica eventos (ex.: `order.created`, `invoice.created`, `stock.updated`) para popular View Tables.
- **Data Warehouse**:
  - Ferramentas como Apache Airflow ou AWS Glue processam eventos e atualizam View Tables.

## Desafios do CQRS e Event Sourcing
1. **Complexidade de Implementação**:
   - Configurar pipelines de *Data Warehouse* e View Tables exige ferramentas adicionais e manutenção.
   - **Solução**: Usar plataformas como Airflow, Kafka Streams ou serviços gerenciados (ex.: AWS Redshift).
2. **Consistência Eventual**:
   - As View Tables podem estar temporariamente dessincronizadas com os bancos de escrita devido a atrasos no processamento de eventos.
   - **Solução**: Monitorar latência do pipeline e configurar alertas para atrasos.
3. **Manutenção de View Tables**:
   - Alterar o formato das View Tables (ex.: adicionar novos campos) exige atualizar pipelines.
   - **Solução**: Padronizar schemas em `contracts` com Zod ou JSON Schema.
4. **Escalabilidade do Banco de Leitura**:
   - View Tables podem crescer significativamente, exigindo bancos otimizados (ex.: Elasticsearch).
   - **Solução**: Usar índices e particionamento no banco de leitura.
5. **Event Sourcing**:
   - Reconstruir estados a partir de eventos pode ser computacionalmente custoso.
   - **Solução**: Usar snapshots periódicos para otimizar reconstrução.

## Boas Práticas
- **Separação de Responsabilidades**:
  - Manter serviços de escrita focados em comandos (CREATE, UPDATE, DELETE) e serviços de leitura focados em consultas (GET).
- **View Tables Otimizadas**:
  - Criar tabelas como `orders_with_invoices` com dados pré-combinados para o front-end.
  - Usar bancos otimizados para leitura (ex.: Elasticsearch, MongoDB).
- **Event Sourcing**:
  - Armazenar eventos em tabelas como `ProductStockOperations` e usar consumidores Kafka para atualizar View Tables.
  - Implementar snapshots para reduzir o custo de reconstrução de estados.
- **Pipelines de Dados**:
  - Usar ferramentas de *Data Warehouse* (ex.: Airflow, Kafka Streams) para processar eventos e popular View Tables.
- **Monitoramento**:
  - Integrar CQRS com **OpenTelemetry** para rastrear eventos e atualizações de View Tables no Jaeger/Grafana.
  - Configurar alertas para atrasos ou erros no pipeline (ex.: via Prometheus).
- **Documentação**:
  - Detalhar CQRS e Event Sourcing na pasta `docs`, incluindo schemas de View Tables e fluxos de eventos.
  - Referenciar padrões no [Microservices.io](https://microservices.io/patterns/data/cqrs.html).

## Relação com o Kubernetes
- **Conexão com o Módulo Anterior**:
  - Serviços de escrita (Pedidos, Notas Fiscais, Estoque) e o serviço de leitura são **Deployments** no Kubernetes.
  - **ConfigMaps** armazenam configurações de pipelines Kafka e bancos de leitura.
  - **Services** garantem comunicação entre serviços de escrita, consumidores Kafka e o banco de leitura.
  - **HPA** escala o serviço de leitura e consumidores Kafka com base na carga.
- **Ferramentas**:
  - **Lens**: Visualiza *Deployments*, *Services* e bancos de leitura.
  - **kubectl** (ou `k`): Gerencia implantação de serviços e pipelines.

## Relação com Outros Conceitos
- **BFF**:
  - CQRS é uma alternativa ao BFF, usando View Tables pré-populadas em vez de chamadas síncronas.
  - Pode ser combinado com BFF para casos específicos que exigem personalização adicional.
- **Saga Pattern**:
  - CQRS complementa Sagas, usando eventos (ex.: `order.created`) para atualizar View Tables.
- **Idempotência**:
  - Consumidores Kafka usam `event_id` para evitar duplicação ao processar eventos para View Tables.
- **Observabilidade**:
  - Eventos e atualizações de View Tables são rastreados com **OpenTelemetry** no Jaeger/Grafana, usando `X-Request-Id` e `event_id`.
- **API Gateway**:
  - O API Gateway roteia requisições GET do front-end para o serviço de leitura e valida JWTs.
- **Autenticação**:
  - O serviço de leitura usa `user_id` (do JWT) para filtrar dados nas View Tables.

## Próximas Aulas
- **Temas Futuros**:
  - Implementação prática de CQRS e Event Sourcing no projeto do GitHub.
  - Configuração de pipelines de *Data Warehouse* com Kafka e Airflow.
  - Otimização de View Tables para alta escalabilidade.
- **Objetivo**:
  - Explorar a implementação de CQRS no projeto.
  - Aprofundar o monitoramento de pipelines e View Tables.

## Conclusão
A aula apresenta o **CQRS** como uma solução para combinar dados de múltiplos serviços, separando comandos (escrita) de consultas (leitura) e usando View Tables otimizadas. O **Event Sourcing** complementa, armazenando eventos em vez de estados finais, com pipelines Kafka populando as View Tables. O exemplo de Pedidos, Notas Fiscais e Estoque ilustra como reduzir latência e complexidade no front-end. Embora não implementado diretamente no projeto, o conceito é detalhado na pasta `docs` e no [Microservices.io](https://microservices.io/patterns/data/cqrs.html). Boas práticas incluem View Tables otimizadas, pipelines robustos e monitoramento. A integração com Kubernetes e conceitos anteriores (BFF, Saga, idempotência) reforça a aplicabilidade, e as próximas aulas explorarão implementações práticas.